# Environment Variables Template
# Copy this file to .env and fill in your values if needed

# Ollama Configuration (defaults work for local installation)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Future: Add API keys here if you want to use cloud LLMs
# OPENAI_API_KEY=your-openai-key-here
# ANTHROPIC_API_KEY=your-anthropic-key-here

# MCP Server Configuration
# Add any environment variables needed by your MCP servers here
